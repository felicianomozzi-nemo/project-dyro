# ğŸ¤– Dyro

This project is a prototype of a **conversational assistant** that allows users to query internal documentation using natural language.
The assistant uses a **RAG (Retrieval-Augmented Generation)** pipeline with embeddings, semantic search, and a language model.

---

## ğŸ“‚ Project Structure

```
project/
â”‚
â”œâ”€â”€ docs/                # Folder containing PDFs organized by category
â”‚   â””â”€â”€ Products/
â”‚       â””â”€â”€ Hotels/
â”‚           â”œâ”€â”€ hotel1.pdf
â”‚           â””â”€â”€ hotel2.pdf
â”‚
â”œâ”€â”€ ingest.py            # Script that processes PDFs and builds the index
â”œâ”€â”€ app.py               # Streamlit web interface for interacting with the assistant
â”œâ”€â”€ requirements.txt     # Project dependencies
â””â”€â”€ .pylintrc            # Pylint configuration for code quality checks
```

---

## âš™ï¸ Installation

1. **Clone the repository**

   ```bash
   git clone <REPO_URL>
   cd project
   ```

2. **Create and activate a virtual environment**

   ```bash
   python -m venv venv
   source venv/bin/activate   # Linux/Mac
   venv\Scripts\activate      # Windows
   ```

3. **Install dependencies**

   ```bash
   pip install -r requirements.txt
   ```

4. **Install Ollama** (to run a local language model)

   * [Download Ollama](https://ollama.ai/)
   * Once installed, make sure you have a model available, for example:

     ```bash
     ollama run llama3
     ```

---

## ğŸš€ Usage

1. **Prepare your documents**
   Place your PDFs inside the `docs/` folder, following the folder structure you want to reflect.

2. **Ingest the documents and build the index**

   ```bash
   python ingest.py
   ```

   This will create a `store.pkl` file containing the extracted text and the semantic index.

3. **Run the web application**

   ```bash
   streamlit run app.py
   ```

4. **Open your browser**
   The interface will be available at [http://localhost:8501](http://localhost:8501).

---

## ğŸ§° Technologies Used

* [Streamlit](https://streamlit.io/) â†’ fast and simple web interface.
* [Sentence Transformers](https://www.sbert.net/) â†’ embedding generation.
* [FAISS](https://faiss.ai/) â†’ semantic search.
* [Ollama](https://ollama.ai/) â†’ local execution of language models (e.g., Llama 3).
* [PyPDF](https://pypi.org/project/pypdf/) â†’ text extraction from PDF files.

---

## ğŸ“ Notes

* The project is configured with **Pylint** (`.pylintrc`) to maintain a consistent coding style.
* This prototype does not include authentication or access control â€” do not use it in production without additional security measures.
* The accuracy of responses depends on the quality of the documents and the language model used.